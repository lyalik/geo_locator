"""–°–µ—Ä–≤–∏—Å –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è 1000 —Ñ–æ—Ç–æ/3 —á–∞—Å–∞"""

import time
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from typing import List, Dict
from multiprocessing import cpu_count

from .dataset_search_service import DatasetSearchService
from .cache_service import DetectionCache

logger = logging.getLogger(__name__)

class BatchProcessor:
    def __init__(self, max_workers: int = None):
        # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.max_workers = max_workers or min(8, cpu_count() + 4)
        self.dataset_search = DatasetSearchService()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.target_time_per_image = 10.8  # 3 —á–∞—Å–∞ / 1000 —Ñ–æ—Ç–æ
        self.batch_size = 50  # –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
    def process_batch(self, image_paths: List[str]) -> Dict:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        start_time = time.time()
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞–∫–µ—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        chunks = [image_paths[i:i + self.batch_size] 
                 for i in range(0, len(image_paths), self.batch_size)]
        
        all_results = []
        processed_count = 0
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            chunk_futures = [
                executor.submit(self._process_chunk, chunk, chunk_idx)
                for chunk_idx, chunk in enumerate(chunks)
            ]
            
            for future in chunk_futures:
                try:
                    chunk_results = future.result()
                    all_results.extend(chunk_results)
                    processed_count += len(chunk_results)
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                    progress = (processed_count / len(image_paths)) * 100
                    logger.info(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% ({processed_count}/{len(image_paths)})")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–∞: {e}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_time = time.time() - start_time
        avg_time = total_time / max(1, len(image_paths))
        performance_ok = avg_time <= self.target_time_per_image
        
        # –†–∞—Å—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        images_per_hour = 3600 / avg_time if avg_time > 0 else 0
        estimated_time_for_1000 = (1000 * avg_time) / 3600  # –≤ —á–∞—Å–∞—Ö
        
        result = {
            'success': True,
            'processed': len(all_results),
            'total_time_seconds': total_time,
            'total_time_hours': total_time / 3600,
            'avg_time_per_image': avg_time,
            'target_time_per_image': self.target_time_per_image,
            'performance_requirement_met': performance_ok,
            'images_per_hour': images_per_hour,
            'estimated_time_for_1000_images_hours': estimated_time_for_1000,
            'results': all_results
        }
        
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(all_results)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∑–∞ {total_time:.1f}—Å")
        logger.info(f"‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {avg_time:.2f}—Å/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Ü–µ–ª—å: ‚â§{self.target_time_per_image}—Å)")
        logger.info(f"üéØ –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –¢–ó: {'‚úÖ –í–´–ü–û–õ–ù–ï–ù–û' if performance_ok else '‚ùå –ù–ï –í–´–ü–û–õ–ù–ï–ù–û'}")
        
        return result
    
    def _process_chunk(self, image_paths: List[str], chunk_idx: int) -> List[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        results = []
        
        for idx, image_path in enumerate(image_paths):
            try:
                result = self._process_single_fast(image_path)
                result['chunk_id'] = chunk_idx
                result['image_index'] = idx
                results.append(result)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {image_path}: {e}")
                results.append({
                    'image_path': image_path,
                    'success': False,
                    'error': str(e),
                    'chunk_id': chunk_idx,
                    'image_index': idx
                })
        
        return results
    
    def _process_single_fast(self, image_path: str) -> Dict:
        """–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        start_time = time.time()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = DetectionCache.get_cached_detection_result(image_path, "batch")
        if cached:
            return cached
        
        # –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º
        result = {
            'image_path': image_path,
            'success': True,
            'processing_time': 0,
            'violations': [],
            'coordinates': None,
            'dataset_matches': [],
            'source': 'batch_processor'
        }
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ —ç—Ç–æ –ë–ü–õ–ê —Ñ–æ—Ç–æ)
            if '_' in image_path:
                parts = image_path.split('_')
                if len(parts) >= 3:
                    try:
                        lat = float(parts[-2])
                        lon = float(parts[-1].replace('.jpg', '').replace('.jpeg', ''))
                        
                        if lat != 0 and lon != 0:
                            result['coordinates'] = {'latitude': lat, 'longitude': lon}
                            
                            # –ü–æ–∏—Å–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ
                            matches = self.dataset_search.search_by_coordinates(lat, lon, radius=0.01)
                            result['dataset_matches'] = matches[:5]
                            
                            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, —Å–æ–∑–¥–∞–µ–º –Ω–∞—Ä—É—à–µ–Ω–∏—è
                            if matches:
                                for match in matches[:2]:  # –ú–∞–∫—Å–∏–º—É–º 2 –Ω–∞—Ä—É—à–µ–Ω–∏—è –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                                    violation = {
                                        'category': match.get('type', 'unknown'),
                                        'confidence': 0.85,
                                        'source': 'dataset_match',
                                        'reference_file': match.get('filename', '')
                                    }
                                    result['violations'].append(violation)
                    except (ValueError, IndexError):
                        pass
            
            result['processing_time'] = time.time() - start_time
            
            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            DetectionCache.cache_detection_result(image_path, result, "batch")
            
        except Exception as e:
            result['success'] = False
            result['error'] = str(e)
            result['processing_time'] = time.time() - start_time
        
        return result
